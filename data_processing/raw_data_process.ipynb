{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first four FRD\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "FirstRateData = os.listdir(\"/data/workspace_files/FirstRateData/\")\n",
    "FirstRateData.remove(\"readme.txt\")\n",
    "FirstRateData.remove(\"B6_EW.zip\")\n",
    "FirstRateData.remove(\"SI_YM.zip\")\n",
    "FirstRateData.remove(\"GC_HG.zip\")\n",
    "FirstRateData.remove(\"LBS_SDA.zip\")\n",
    "FirstRateData.remove(\"ZC_ZW.zip\")\n",
    "FirstRateData.remove(\"A6_AD_B0_B6.zip\")\n",
    "\n",
    "while len(FirstRateData) > 0:\n",
    "    current_file = []\n",
    "    current_file.append(FirstRateData[0])\n",
    "    FirstRateData.remove(current_file[0])\n",
    "    for i in range(len(FirstRateData)-1,-1,-1):\n",
    "        if FirstRateData[i][0:3] == current_file[0][0:3]:\n",
    "            current_file.append(FirstRateData[i])\n",
    "            FirstRateData.remove(FirstRateData[i])\n",
    "    \n",
    "    print(current_file)\n",
    "    # #TODO\n",
    "    # if len(current_file) < 3:\n",
    "    #     continue\n",
    "    \n",
    "    current_file = sorted(current_file)\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(current_file)):\n",
    "        data_tmp = pd.read_csv('/data/workspace_files/FirstRateData/' + current_file[i], sep=\",\", header=None)\n",
    "        data_tmp.columns = [\"DateTime\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        data_tmp = data_tmp.set_index('DateTime')\n",
    "        data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "        frames.append(data_tmp)\n",
    "\n",
    "    data = pd.concat(frames)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "    hour_prior_volume = []\n",
    "    hour_prior_range_high = []\n",
    "    hour_prior_range_low = []\n",
    "    overnight_range_high = []\n",
    "    overnight_range_low = []\n",
    "    overnight_volume = []\n",
    "\n",
    "    new_data = []\n",
    "\n",
    "    new_data.append([\"DateTime\", \"hour_prior_volume\", \"hour_prior_range\", \"overnight_range\", \"overnight_volume\"])\n",
    "    year = -1\n",
    "    month = -1\n",
    "    day = -1\n",
    "    prev_index = -1\n",
    "    for index, row in data.iterrows():\n",
    "        if year == -1:\n",
    "            year = index.year\n",
    "            month = index.month\n",
    "            day = index.day\n",
    "            prev_index = index\n",
    "        if index.year == year and index.month == month and index.day == day:\n",
    "            \n",
    "            if (index.hour == 5 and index.minute >= 30) or (index.hour == 6 and index.minute <= 30):\n",
    "                hour_prior_volume.append(row['Volume'])\n",
    "            \n",
    "            if (index.hour == 8 and index.minute >= 30) or (index.hour == 9 and index.minute <= 30):\n",
    "                hour_prior_range_high.append(row['High'])\n",
    "                hour_prior_range_low.append(row['Low'])\n",
    "\n",
    "            if (index.hour >= 16):\n",
    "                overnight_range_high.append(row['High'])\n",
    "                overnight_range_low.append(row['Low'])\n",
    "                overnight_volume.append(row['Volume'])\n",
    "        else:\n",
    "            #TODO\n",
    "            if (index.hour <= 9) or (index.hour == 9 and index.minute <= 30):\n",
    "                overnight_range_high.append(row['High'])\n",
    "                overnight_range_low.append(row['Low']) \n",
    "                overnight_volume.append(row['Volume'])\n",
    "\n",
    "            if len(hour_prior_volume) != 0 or len(hour_prior_range_high)!= 0 or len(overnight_range_high) !=0 or len(overnight_volume) != 0:\n",
    "                new_data.append([str(prev_index.year)+\"-\"+str(prev_index.month)+\"-\"+str(prev_index.day),\n",
    "                             sum(hour_prior_volume),\n",
    "                             (max(hour_prior_range_high) - min(hour_prior_range_low)) if len(hour_prior_range_high) != 0 else -1,\n",
    "                             (max(overnight_range_high) - min(overnight_range_low)) if len(overnight_range_high) != 0 else -1,\n",
    "                             sum(overnight_volume)])\n",
    "            \n",
    "            hour_prior_volume = []\n",
    "            hour_prior_range_high = []\n",
    "            hour_prior_range_low = []\n",
    "            overnight_range_high = []\n",
    "            overnight_range_low = []\n",
    "            overnight_volume = []\n",
    "            \n",
    "            year = index.year\n",
    "            month = index.month\n",
    "            day = index.day\n",
    "            prev_index = index\n",
    "\n",
    "\n",
    "    str_tmp = str(current_file[0][0:3])\n",
    "    \n",
    "    split_string = str_tmp.split(\".\", 1)\n",
    "    split_string = split_string[0].split(\"_\", 1)\n",
    "    \n",
    "    str_tmp = split_string[0]\n",
    "    print(str_tmp)\n",
    "    with open(\"FirstRateData/\" + str_tmp + \".csv\", \"w+\") as my_csv:\n",
    "        csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "        csvWriter.writerows(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first four kibot\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "# FirstRateData = os.listdir(\"/data/workspace_files/Kibot/\")\n",
    "\n",
    "FirstRateData = [\"JY.txt\", \"US.txt\", \"NG.txt\", \"NE.txt\", \"M6E.txt\", \"NIY.txt\", \"QM.txt\", \"PX.txt\", \"HO.txt\", \"NKD.txt\", \"MGC.txt\",\n",
    "\"M6A.txt\", \"M6B.txt\", \"JE.txt\", \"MJY.txt\", \"RP.txt\", \"RY.txt\", \"MCD.txt\", \"RF.txt\", \"BR.txt\", \"RU.txt\", \"RA.txt\", \"XAE.txt\", \"XAF.txt\",\n",
    "\"XAU.txt\", \"XAV.txt\", \"XAY.txt\", \"XAK.txt\", \"XAI.txt\", \"MSF.txt\", \"XAP.txt\", \"XAB.txt\", \"SEK.txt\", \"AC.txt\", \"NOK.txt\", \"AJY.txt\",\n",
    "\"PJY.txt\", \"EAD.txt\", \"ECD.txt\"]\n",
    "\n",
    "while len(FirstRateData) > 0:\n",
    "    current_file = []\n",
    "    current_file.append(FirstRateData[0])\n",
    "    FirstRateData.remove(current_file[0])\n",
    "    for i in range(len(FirstRateData)-1,-1,-1):\n",
    "        if FirstRateData[i][0:3] == current_file[0][0:3]:\n",
    "            current_file.append(FirstRateData[i])\n",
    "            FirstRateData.remove(FirstRateData[i])\n",
    "    \n",
    "    print(current_file)\n",
    "    \n",
    "    current_file = sorted(current_file)\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(current_file)):\n",
    "\n",
    "        data_tmp = pd.read_csv('/data/workspace_files/Kibot/' + current_file[i], sep=\",\", header=None)\n",
    "        data_tmp.columns = [\"year\", \"time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        data_tmp[\"DateTime\"] = data_tmp[\"year\"] + data_tmp[\"time\"]\n",
    "        data_tmp = data_tmp.drop(['year', 'time'], axis=1)\n",
    "        \n",
    "        ll = data_tmp.values.tolist()\n",
    "\n",
    "        for i3 in range(len(ll)):\n",
    "            strr = ll[i3][5]\n",
    "            mm = strr[0:2]\n",
    "            dd = strr[3:5]\n",
    "            yy = strr[6:10]\n",
    "            tt = strr[10:]\n",
    "            ff_strr = yy + \"-\" + mm + \"-\" + dd + \" \" + tt\n",
    "            ll[i3][5] = ff_strr\n",
    "        \n",
    "        from pandas import DataFrame\n",
    "\n",
    "        data_tmp = DataFrame(ll,columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"DateTime\"])\n",
    "        data_tmp = data_tmp.set_index('DateTime')\n",
    "        data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "        frames.append(data_tmp)\n",
    "\n",
    "    data = pd.concat(frames)\n",
    "\n",
    "    # print(data)\n",
    "\n",
    "    hour_prior_volume = []\n",
    "    hour_prior_range_high = []\n",
    "    hour_prior_range_low = []\n",
    "    overnight_range_high = []\n",
    "    overnight_range_low = []\n",
    "    overnight_volume = []\n",
    "\n",
    "    new_data = []\n",
    "\n",
    "    new_data.append([\"DateTime\", \"hour_prior_volume\", \"hour_prior_range\", \"overnight_range\", \"overnight_volume\"])\n",
    "    year = -1\n",
    "    month = -1\n",
    "    day = -1\n",
    "    prev_index = -1\n",
    "    for index, row in data.iterrows():\n",
    "        if year == -1:\n",
    "            year = index.year\n",
    "            month = index.month\n",
    "            day = index.day\n",
    "            prev_index = index\n",
    "        if index.year == year and index.month == month and index.day == day:\n",
    "            \n",
    "            if (index.hour == 5 and index.minute >= 30) or (index.hour == 6 and index.minute <= 30):\n",
    "                hour_prior_volume.append(row['Volume'])\n",
    "            \n",
    "            if (index.hour == 8 and index.minute >= 30) or (index.hour == 9 and index.minute <= 30):\n",
    "                hour_prior_range_high.append(row['High'])\n",
    "                hour_prior_range_low.append(row['Low'])\n",
    "\n",
    "            if (index.hour >= 16):\n",
    "                overnight_range_high.append(row['High'])\n",
    "                overnight_range_low.append(row['Low'])\n",
    "                overnight_volume.append(row['Volume'])\n",
    "        else:\n",
    "            #TODO\n",
    "            if (index.hour <= 9) or (index.hour == 9 and index.minute <= 30):\n",
    "                overnight_range_high.append(row['High'])\n",
    "                overnight_range_low.append(row['Low']) \n",
    "                overnight_volume.append(row['Volume'])\n",
    "\n",
    "            if len(hour_prior_volume) != 0 or len(hour_prior_range_high)!= 0 or len(overnight_range_high) !=0 or len(overnight_volume) != 0:\n",
    "                new_data.append([str(prev_index.year)+\"-\"+str(prev_index.month)+\"-\"+str(prev_index.day),\n",
    "                             sum(hour_prior_volume),\n",
    "                             (max(hour_prior_range_high) - min(hour_prior_range_low)) if len(hour_prior_range_high) != 0 else -1,\n",
    "                             (max(overnight_range_high) - min(overnight_range_low)) if len(overnight_range_high) != 0 else -1,\n",
    "                             sum(overnight_volume)])\n",
    "            \n",
    "            hour_prior_volume = []\n",
    "            hour_prior_range_high = []\n",
    "            hour_prior_range_low = []\n",
    "            overnight_range_high = []\n",
    "            overnight_range_low = []\n",
    "            overnight_volume = []\n",
    "            \n",
    "            year = index.year\n",
    "            month = index.month\n",
    "            day = index.day\n",
    "            prev_index = index\n",
    "\n",
    "\n",
    "    str_tmp = str(current_file[0][0:3])\n",
    "    print(\"kibot/\" + str_tmp + \".csv\")\n",
    "\n",
    "    split_string = str_tmp.split(\".\", 1)\n",
    "\n",
    "    str_tmp = split_string[0]\n",
    "\n",
    "    with open(\"kibot/\" + str_tmp + \".csv\", \"w+\") as my_csv:\n",
    "        csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "        csvWriter.writerows(new_data)\n",
    "        print(\"kibot/\" + str_tmp + \".csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rest FRD\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "tmptmp = 0\n",
    "while tmptmp < 1:\n",
    "    tmptmp = 1\n",
    "\n",
    "    current_file = [\"ZT_2000_2009.txt\", \"ZT_2010_2019.txt\", \"ZT_2020_2020.txt\"]\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(current_file)):\n",
    "        data_tmp = pd.read_csv('/data/workspace_files/FirstRateData/' + current_file[i], sep=\",\", header=None)\n",
    "        data_tmp.columns = [\"DateTime\", \"Open_2\", \"High_2\", \"Low_2\", \"Close_2\", \"Volume_2\"]\n",
    "        data_tmp = data_tmp.set_index('DateTime')\n",
    "        data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "        frames.append(data_tmp)\n",
    "\n",
    "    data_2 = pd.concat(frames)\n",
    "\n",
    "    current_file = [\"ZF_2000_2009.txt\", \"ZF_2010_2019.txt\", \"ZF_2020_2020.txt\"]\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(current_file)):\n",
    "        data_tmp = pd.read_csv('/data/workspace_files/FirstRateData/' + current_file[i], sep=\",\", header=None)\n",
    "        data_tmp.columns = [\"DateTime\", \"Open_5\", \"High_5\", \"Low_5\", \"Close_5\", \"Volume_5\"]\n",
    "        data_tmp = data_tmp.set_index('DateTime')\n",
    "        data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "        frames.append(data_tmp)\n",
    "\n",
    "    data_5 = pd.concat(frames)\n",
    "\n",
    "    current_file = [\"ZN_2000_2009.txt\", \"ZN_2010_2019.txt\", \"ZN_2020_2020.txt\"]\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(current_file)):\n",
    "        data_tmp = pd.read_csv('/data/workspace_files/FirstRateData/' + current_file[i], sep=\",\", header=None)\n",
    "        data_tmp.columns = [\"DateTime\", \"Open_10\", \"High_10\", \"Low_10\", \"Close_10\", \"Volume_10\"]\n",
    "        data_tmp = data_tmp.set_index('DateTime')\n",
    "        data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "        frames.append(data_tmp)\n",
    "\n",
    "    data_10 = pd.concat(frames)\n",
    "\n",
    "    current_file = [\"US.txt\"]\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(current_file)):\n",
    "        data_tmp = pd.read_csv('/data/workspace_files/Kibot/' + current_file[i], sep=\",\", header=None)\n",
    "        data_tmp.columns = [\"year\", \"time\", \"Open_30\", \"High_30\", \"Low_30\", \"Close_30\", \"Volume_30\"]\n",
    "        data_tmp[\"DateTime\"] = data_tmp[\"year\"] + data_tmp[\"time\"]\n",
    "        data_tmp = data_tmp.drop(['year', 'time'], axis=1)\n",
    "        \n",
    "        ll = data_tmp.values.tolist()\n",
    "\n",
    "        for i3 in range(len(ll)):\n",
    "            strr = ll[i3][5]\n",
    "            mm = strr[0:2]\n",
    "            dd = strr[3:5]\n",
    "            yy = strr[6:10]\n",
    "            tt = strr[10:]\n",
    "            ff_strr = yy + \"-\" + mm + \"-\" + dd + \" \" + tt\n",
    "            ll[i3][5] = ff_strr\n",
    "        \n",
    "        from pandas import DataFrame\n",
    "\n",
    "        data_tmp = DataFrame(ll,columns=[\"Open_30\", \"High_30\", \"Low_30\", \"Close_30\", \"Volume_30\", \"DateTime\"])\n",
    "        data_tmp = data_tmp.set_index('DateTime')\n",
    "        data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "        frames.append(data_tmp)\n",
    "\n",
    "    data_30 = pd.concat(frames)\n",
    "\n",
    "    data = pd.concat([data_2, data_5, data_10, data_30], axis=1)\n",
    "\n",
    "    print(data)\n",
    " \n",
    "    # data.to_csv(\"test.csv\")\n",
    " \n",
    "    b_10_5_year_overnight = []\n",
    "    b_10_5_year_hourprior = []\n",
    "    b_10_5_year_hour_to_open = []\n",
    "    ten_is_increase_hour = -1\n",
    "    ten_is_decrease_hour = -1\n",
    "    ten_is_increase_hour_open = -1\n",
    "    ten_is_decrease_hour_open = -1\n",
    "\n",
    "    b_5_2_year_overnight = []\n",
    "    b_5_2_year_hourprior = []\n",
    "    b_5_2_year_hour_to_open = []\n",
    "    five_is_increase_hour = -1\n",
    "    five_is_decrease_hour = -1\n",
    "    five_is_increase_hour_open = -1\n",
    "    five_is_decrease_hour_open = -1\n",
    "\n",
    "    b_30_10_year_overnight = []\n",
    "    b_30_10_year_hourprior = []\n",
    "    b_30_10_year_hour_to_open = []\n",
    "    thirty_is_increase_hour = -1\n",
    "    thirty_is_decrease_hour = -1\n",
    "    thirty_is_increase_hour_open = -1\n",
    "    thirty_is_decrease_hour_open = -1\n",
    "\n",
    "    new_data = []\n",
    "\n",
    "    new_data.append([\"DateTime\", \"10_5_year_overnight\", \"10_5_year_hourprior\", \"10_5_year_hour_to_open\", \"ten_is_increase_hour\",\n",
    "                     \"ten_is_decrease_hour\", \"ten_is_increase_hour_open\", \"ten_is_decrease_hour_open\",\n",
    "                     \"5_2_year_overnight\", \"5_2_year_hourprior\", \"5_2_year_hour_to_open\", \"five_is_increase_hour\",\n",
    "                     \"five_is_decrease_hour\", \"five_is_increase_hour_open\", \"five_is_decrease_hour_open\",\n",
    "                     \"30_10_year_overnight\", \"30_10_year_hourprior\", \"30_10_year_hour_to_open\",\n",
    "                     \"thirty_is_increase_hour\", \"thirty_is_decrease_hour\", \"thirty_is_increase_hour_open\",\n",
    "                     \"thirty_is_decrease_hour_open\"                \n",
    "                     ])\n",
    "    year = -1\n",
    "    month = -1\n",
    "    day = -1\n",
    "    prev_index = -1\n",
    "    for index, row in data.iterrows():\n",
    "        if year == -1:\n",
    "            year = index.year\n",
    "            month = index.month\n",
    "            day = index.day\n",
    "            prev_index = index\n",
    "        if index.year == year and index.month == month and index.day == day:\n",
    "\n",
    "            if index.hour >= 16 and len(b_10_5_year_overnight) == 0 and (not math.isnan(row['High_10'])) and (not math.isnan(row['High_5'])):\n",
    "                b_10_5_year_overnight.append(row['High_10'] - row['High_5'])\n",
    "            if index.hour == 8 and index.minute == 30 and (not math.isnan(row['High_10'])) and (not math.isnan(row['High_5'])):\n",
    "                b_10_5_year_hourprior.append(row['High_10'] - row['High_5'])\n",
    "            if index.hour == 9 and index.minute == 30 and (not math.isnan(row['High_10'])) and (not math.isnan(row['High_5'])):\n",
    "                b_10_5_year_hour_to_open.append(row['High_10'] - row['High_5'])\n",
    "\n",
    "            if index.hour >= 16 and len(b_5_2_year_overnight) == 0 and (not math.isnan(row['High_5'])) and (not math.isnan(row['High_2'])):\n",
    "                b_5_2_year_overnight.append(row['High_5'] - row['High_2'])\n",
    "            if index.hour == 8 and index.minute == 30 and (not math.isnan(row['High_5'])) and (not math.isnan(row['High_2'])):\n",
    "                b_5_2_year_hourprior.append(row['High_5'] - row['High_2'])\n",
    "            if index.hour == 9 and index.minute == 30 and (not math.isnan(row['High_5'])) and (not math.isnan(row['High_2'])):\n",
    "                b_5_2_year_hour_to_open.append(row['High_5'] - row['High_2'])\n",
    "\n",
    "            if index.hour >= 16 and len(b_30_10_year_overnight) == 0 and (not math.isnan(row['High_30'])) and (not math.isnan(row['High_10'])):\n",
    "                b_30_10_year_overnight.append(row['High_30'] - row['High_10'])\n",
    "            if index.hour == 8 and index.minute == 30 and (not math.isnan(row['High_30'])) and (not math.isnan(row['High_10'])):\n",
    "                b_30_10_year_hourprior.append(row['High_30'] - row['High_10'])\n",
    "            if index.hour == 9 and index.minute == 30 and (not math.isnan(row['High_30'])) and (not math.isnan(row['High_10'])):\n",
    "                b_30_10_year_hour_to_open.append(row['High_30'] - row['High_10'])\n",
    "            \n",
    "        else:\n",
    "            if len(b_10_5_year_overnight) > 0 and len(b_10_5_year_hour_to_open) > 0:\n",
    "                if b_10_5_year_overnight[0] > b_10_5_year_hour_to_open[0]:\n",
    "                    ten_is_increase_hour = 1\n",
    "                else:\n",
    "                    ten_is_increase_hour = 0    \n",
    "\n",
    "            if len(b_10_5_year_overnight) > 0 and len(b_10_5_year_hour_to_open) > 0:\n",
    "                if b_10_5_year_overnight[0] > b_10_5_year_hour_to_open[0]:\n",
    "                    ten_is_decrease_hour = 0\n",
    "                else:\n",
    "                    ten_is_decrease_hour = 1  \n",
    "\n",
    "            if len(b_10_5_year_hourprior) > 0 and len(b_10_5_year_hour_to_open) > 0:\n",
    "                if b_10_5_year_hour_to_open[0] > b_10_5_year_hourprior[0]:\n",
    "                    ten_is_increase_hour_open = 1\n",
    "                else:\n",
    "                    ten_is_increase_hour_open = 0  \n",
    "\n",
    "            if len(b_10_5_year_hourprior) > 0 and len(b_10_5_year_hour_to_open) > 0:\n",
    "                if b_10_5_year_hour_to_open[0] > b_10_5_year_hourprior[0]:\n",
    "                    ten_is_decrease_hour_open = 1\n",
    "                else:\n",
    "                    ten_is_decrease_hour_open = 0 \n",
    "\n",
    "\n",
    "            if len(b_5_2_year_overnight) > 0 and len(b_5_2_year_hour_to_open) > 0:\n",
    "                if b_5_2_year_overnight[0] > b_5_2_year_hour_to_open[0]:\n",
    "                    five_is_increase_hour = 1\n",
    "                else:\n",
    "                    five_is_increase_hour = 0    \n",
    "\n",
    "            if len(b_5_2_year_overnight) > 0 and len(b_5_2_year_hour_to_open) > 0:\n",
    "                if b_5_2_year_overnight[0] > b_5_2_year_hour_to_open[0]:\n",
    "                    five_is_decrease_hour = 0\n",
    "                else:\n",
    "                    five_is_decrease_hour = 1  \n",
    "\n",
    "            if len(b_5_2_year_hourprior) > 0 and len(b_5_2_year_hour_to_open) > 0:\n",
    "                if b_5_2_year_hour_to_open[0] > b_5_2_year_hourprior[0]:\n",
    "                    five_is_increase_hour_open = 1\n",
    "                else:\n",
    "                    five_is_increase_hour_open = 0  \n",
    "\n",
    "            if len(b_5_2_year_hourprior) > 0 and len(b_5_2_year_hour_to_open) > 0:\n",
    "                if b_5_2_year_hour_to_open[0] > b_5_2_year_hourprior[0]:\n",
    "                    five_is_decrease_hour_open = 1\n",
    "                else:\n",
    "                    five_is_decrease_hour_open = 0 \n",
    "\n",
    "\n",
    "            if len(b_30_10_year_overnight) > 0 and len(b_30_10_year_hour_to_open) > 0:\n",
    "                if b_30_10_year_overnight[0] > b_30_10_year_hour_to_open[0]:\n",
    "                    thirty_is_increase_hour = 1\n",
    "                else:\n",
    "                    thirty_is_increase_hour = 0    \n",
    "\n",
    "            if len(b_30_10_year_overnight) > 0 and len(b_30_10_year_hour_to_open) > 0:\n",
    "                if b_30_10_year_overnight[0] > b_30_10_year_hour_to_open[0]:\n",
    "                    thirty_is_decrease_hour = 0\n",
    "                else:\n",
    "                    thirty_is_decrease_hour = 1  \n",
    "\n",
    "            if len(b_30_10_year_hourprior) > 0 and len(b_30_10_year_hour_to_open) > 0:\n",
    "                if b_30_10_year_hour_to_open[0] > b_30_10_year_hourprior[0]:\n",
    "                    thirty_is_increase_hour_open = 1\n",
    "                else:\n",
    "                    thirty_is_increase_hour_open = 0  \n",
    "\n",
    "            if len(b_30_10_year_hourprior) > 0 and len(b_30_10_year_hour_to_open) > 0:\n",
    "                if b_30_10_year_hour_to_open[0] > b_30_10_year_hourprior[0]:\n",
    "                    thirty_is_decrease_hour_open = 1\n",
    "                else:\n",
    "                    thirty_is_decrease_hour_open = 0 \n",
    "\n",
    "\n",
    "            new_data.append([str(prev_index.year) + \"-\" + str(prev_index.month) + \"-\" + str(prev_index.day),\n",
    "                             b_10_5_year_overnight[0] if len(b_10_5_year_overnight) > 0 else -1,\n",
    "                             b_10_5_year_hourprior[0] if len(b_10_5_year_hourprior) > 0 else -1,\n",
    "                             b_10_5_year_hour_to_open[0] if len(b_10_5_year_hour_to_open) > 0 else -1,\n",
    "                             ten_is_increase_hour,\n",
    "                             ten_is_decrease_hour,\n",
    "                             ten_is_increase_hour_open,\n",
    "                             ten_is_decrease_hour_open,\n",
    "                             b_5_2_year_overnight[0] if len(b_5_2_year_overnight) > 0 else -1,\n",
    "                             b_5_2_year_hourprior[0] if len(b_5_2_year_hourprior) > 0 else -1,\n",
    "                             b_5_2_year_hour_to_open[0] if len(b_5_2_year_hour_to_open) > 0 else -1,\n",
    "                             five_is_increase_hour,\n",
    "                             five_is_decrease_hour,\n",
    "                             five_is_increase_hour_open,\n",
    "                             five_is_decrease_hour_open,\n",
    "                             b_30_10_year_overnight[0] if len(b_30_10_year_overnight) > 0 else -1,\n",
    "                             b_30_10_year_hourprior[0] if len(b_30_10_year_hourprior) > 0 else -1,\n",
    "                             b_30_10_year_hour_to_open[0] if len(b_30_10_year_hour_to_open) > 0 else -1,\n",
    "                             thirty_is_increase_hour,\n",
    "                             thirty_is_decrease_hour,\n",
    "                             thirty_is_increase_hour_open,\n",
    "                             thirty_is_decrease_hour_open\n",
    "                             ])\n",
    "            \n",
    "            \n",
    "            year = index.year\n",
    "            month = index.month\n",
    "            day = index.day\n",
    "            prev_index = index\n",
    "\n",
    "\n",
    "    str_tmp = str(current_file[0][0:3])\n",
    "\n",
    "    with open(\"FirstRateData/bounds.csv\", \"w+\") as my_csv:\n",
    "        csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "        csvWriter.writerows(new_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FRD = [\"ES.csv\", \"NQ.csv\", \"A6.csv\", \"B6.csv\", \"BTC.csv\", \"CL.csv\", \"E6.csv\", \"ED.csv\", \"GC.csv\", \"HG.csv\", \"ME.csv\", \n",
    "        \"MES.csv\", \"PL.csv\", \"RTY.csv\", \"SI.csv\", \"VX.csv\", \"YM.csv\", \"ZC.csv\", \"ZS.csv\", \"EW.csv\", \"ZF.csv\", \"ZN.csv\",\n",
    "        \"ZT.csv\", \"LBS.csv\", \"LE.csv\", \"HE.csv\", \"ZW.csv\", \"PA.csv\", \"E1.csv\", \"MP.csv\", \"AD.csv\", \"UB.csv\", \"ZQ.csv\",\n",
    "        \"ZL.csv\", \"ZM.csv\", \"RB.csv\", \"BZ.csv\"]\n",
    "\n",
    "Kibot = [\"JY.csv\", \"US.csv\", \"NG.csv\", \"NE.csv\", \"M6E.csv\", \"NIY.csv\", \"QM.csv\", \"PX.csv\", \"HO.csv\", \"NKD.csv\", \"MGC.csv\",\n",
    "        \"M6A.csv\", \"M6B.csv\", \"JE.csv\", \"MJY.csv\", \"RP.csv\", \"RY.csv\", \"MCD.csv\", \"RF.csv\", \"BR.csv\", \"RU.csv\", \"RA.csv\", \"XAE.csv\", \"XAF.csv\",\n",
    "        \"XAU.csv\", \"XAV.csv\", \"XAY.csv\", \"XAK.csv\", \"XAI.csv\", \"MSF.csv\", \"XAP.csv\", \"XAB.csv\", \"SEK.csv\", \"AC.csv\", \"NOK.csv\", \"AJY.csv\",\n",
    "        \"PJY.csv\", \"EAD.csv\", \"ECD.csv\"]\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, len(FRD)):\n",
    "    split_string = FRD[i].split(\".\", 1)\n",
    "    \n",
    "    data_tmp = pd.read_csv('/data/workspace_files/processed_data/FirstRateData/' + FRD[i], sep=\",\", header=None)\n",
    "    data_tmp.columns = [\"DateTime\", split_string[0]+\"_hour_prior_volume\", split_string[0]+\"_hour_prior_range\", \n",
    "                        split_string[0]+\"_overnight_range\", split_string[0]+\"_overnight_volume\"]\n",
    "    data_tmp = data_tmp.iloc[1:]\n",
    "    data_tmp = data_tmp.set_index('DateTime')\n",
    "    data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "\n",
    "    if split_string[0] == \"BTC\" or split_string[0] == \"MES\":\n",
    "        data_tmp = data_tmp.loc[~data_tmp.index.duplicated(keep='first')]\n",
    "    # print(data_tmp[data_tmp.index.duplicated()])\n",
    "    frames.append(data_tmp)\n",
    "\n",
    "for i in range(0, len(Kibot)):\n",
    "    split_string = Kibot[i].split(\".\", 1)\n",
    "    \n",
    "    data_tmp = pd.read_csv('/data/workspace_files/processed_data/kibot/' + Kibot[i], sep=\",\", header=None)\n",
    "    data_tmp.columns = [\"DateTime\", split_string[0]+\"_hour_prior_volume\", split_string[0]+\"_hour_prior_range\", \n",
    "                        split_string[0]+\"_overnight_range\", split_string[0]+\"_overnight_volume\"]\n",
    "    data_tmp = data_tmp.iloc[1:]\n",
    "    data_tmp = data_tmp.set_index('DateTime')\n",
    "    data_tmp.index = pd.to_datetime(data_tmp.index)\n",
    "    # print(data_tmp[data_tmp.index.duplicated(keep=False)])\n",
    "    frames.append(data_tmp)\n",
    "\n",
    "data = pd.concat(frames, axis=1)\n",
    "\n",
    "print(data)\n",
    "\n",
    "data.to_csv('FRD+Kibot.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}